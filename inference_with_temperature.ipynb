{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T16:37:29.166678Z",
     "iopub.status.busy": "2025-05-18T16:37:29.166330Z",
     "iopub.status.idle": "2025-05-18T17:27:16.759685Z",
     "shell.execute_reply": "2025-05-18T17:27:16.758829Z",
     "shell.execute_reply.started": "2025-05-18T16:37:29.166654Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 30000/30000 [49:42<00:00, 10.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLIP-VQA-Base Exact Match Accuracy: 0.2536\n",
      "BLIP-VQA-Base Average BLEU-1 Score: 0.2592\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Question</th>\n",
       "      <th>GroundTruth</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the pattern of the shoe sole? (answer ...</td>\n",
       "      <td>Ridged</td>\n",
       "      <td>stripes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Judging by the image, what is the rust-resista...</td>\n",
       "      <td>Brown</td>\n",
       "      <td>rust</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What color is the lid of the 365 Everyday Valu...</td>\n",
       "      <td>Green</td>\n",
       "      <td>green</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Judging from the image, what color is the \"Who...</td>\n",
       "      <td>White</td>\n",
       "      <td>brown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Considering the Rivet Theresa chair's upholste...</td>\n",
       "      <td>Dotted</td>\n",
       "      <td>tweed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Given the \"Boy and Girl\" design, what shape ar...</td>\n",
       "      <td>Hearts</td>\n",
       "      <td>heart</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Based on the AmazonBasics mat's double-dot tex...</td>\n",
       "      <td>Non-slip</td>\n",
       "      <td>high</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>What color is the handle of the garden tool? (...</td>\n",
       "      <td>Blue</td>\n",
       "      <td>blue</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>What design is printed on the cups? (answer in...</td>\n",
       "      <td>Leaves</td>\n",
       "      <td>leaf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>What color is the plumbing fixture shown in th...</td>\n",
       "      <td>Black</td>\n",
       "      <td>silver</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                           Question GroundTruth  \\\n",
       "0      0  What is the pattern of the shoe sole? (answer ...      Ridged   \n",
       "1      1  Judging by the image, what is the rust-resista...       Brown   \n",
       "2      2  What color is the lid of the 365 Everyday Valu...       Green   \n",
       "3      3  Judging from the image, what color is the \"Who...       White   \n",
       "4      4  Considering the Rivet Theresa chair's upholste...      Dotted   \n",
       "5      5  Given the \"Boy and Girl\" design, what shape ar...      Hearts   \n",
       "6      6  Based on the AmazonBasics mat's double-dot tex...    Non-slip   \n",
       "7      7  What color is the handle of the garden tool? (...        Blue   \n",
       "8      8  What design is printed on the cups? (answer in...      Leaves   \n",
       "9      9  What color is the plumbing fixture shown in th...       Black   \n",
       "\n",
       "  Prediction  BLEU-1  Match  \n",
       "0    stripes     0.0  False  \n",
       "1       rust     0.0  False  \n",
       "2      green     1.0   True  \n",
       "3      brown     0.0  False  \n",
       "4      tweed     0.0  False  \n",
       "5      heart     0.0  False  \n",
       "6       high     0.0  False  \n",
       "7       blue     1.0   True  \n",
       "8       leaf     0.0  False  \n",
       "9     silver     0.0  False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "#  Load CSV and define image path\n",
    "df = pd.read_csv('/kaggle/input/actual-dataset/final.csv')\n",
    "dataset_dir = '/kaggle/input/images/abo-images-small/images/small'\n",
    "\n",
    "# Take a random sample of 30,000 rows\n",
    "df = df.sample(n=30000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Load BLIP VQA base model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(device)\n",
    "\n",
    "# Evaluation setup\n",
    "results = []\n",
    "smoothie = SmoothingFunction().method1\n",
    "bleu_scores = []\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = df.iloc[i]\n",
    "    img_path = os.path.join(dataset_dir, row['path'])\n",
    "\n",
    "    try:\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "    except:\n",
    "        print(f\"Could not open image {img_path}\")\n",
    "        continue\n",
    "\n",
    "    question = str(row['Question']).strip() if pd.notnull(row['Question']) else \"\"\n",
    "    true_answer = str(row['Answer']).strip() if pd.notnull(row['Answer']) else \"\"\n",
    "\n",
    "    question += \" (answer in one word)\"\n",
    "\n",
    "    inputs = processor(image, question, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(**inputs,temperature=0.7)\n",
    "    pred = processor.decode(output[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    reference = [true_answer.lower().split()]\n",
    "    candidate = pred.lower().split()\n",
    "    bleu = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "    bleu_scores.append(bleu)\n",
    "\n",
    "    results.append({\n",
    "        'Index': i,\n",
    "        'Question': question,\n",
    "        'GroundTruth': true_answer,\n",
    "        'Prediction': pred,\n",
    "        'BLEU-1': bleu\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and evaluate\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df['Match'] = res_df.apply(\n",
    "    lambda x: x['GroundTruth'].strip().lower() == x['Prediction'].strip().lower(),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "accuracy = res_df['Match'].mean()\n",
    "average_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "#  Save and show\n",
    "res_df.to_csv('/kaggle/working/blip_vqa_base_30k_sample_results.csv', index=False)\n",
    "print(f\"BLIP-VQA-Base Exact Match Accuracy: {accuracy:.4f}\")\n",
    "print(f\"BLIP-VQA-Base Average BLEU-1 Score: {average_bleu:.4f}\")\n",
    "res_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T17:32:50.457361Z",
     "iopub.status.busy": "2025-05-18T17:32:50.457055Z",
     "iopub.status.idle": "2025-05-18T18:04:49.379448Z",
     "shell.execute_reply": "2025-05-18T18:04:49.378703Z",
     "shell.execute_reply.started": "2025-05-18T17:32:50.457341Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 20000/20000 [31:54<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLIP-VQA-Base Exact Match Accuracy: 0.2565\n",
      "BLIP-VQA-Base Average BLEU-1 Score: 0.2620\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Question</th>\n",
       "      <th>GroundTruth</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>BLEU-1</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the pattern of the shoe sole? (answer ...</td>\n",
       "      <td>Ridged</td>\n",
       "      <td>stripes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Judging by the image, what is the rust-resista...</td>\n",
       "      <td>Brown</td>\n",
       "      <td>rust</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What color is the lid of the 365 Everyday Valu...</td>\n",
       "      <td>Green</td>\n",
       "      <td>green</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Judging from the image, what color is the \"Who...</td>\n",
       "      <td>White</td>\n",
       "      <td>brown</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Considering the Rivet Theresa chair's upholste...</td>\n",
       "      <td>Dotted</td>\n",
       "      <td>tweed</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Given the \"Boy and Girl\" design, what shape ar...</td>\n",
       "      <td>Hearts</td>\n",
       "      <td>heart</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Based on the AmazonBasics mat's double-dot tex...</td>\n",
       "      <td>Non-slip</td>\n",
       "      <td>high</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>What color is the handle of the garden tool? (...</td>\n",
       "      <td>Blue</td>\n",
       "      <td>blue</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>What design is printed on the cups? (answer in...</td>\n",
       "      <td>Leaves</td>\n",
       "      <td>leaf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>What color is the plumbing fixture shown in th...</td>\n",
       "      <td>Black</td>\n",
       "      <td>silver</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                           Question GroundTruth  \\\n",
       "0      0  What is the pattern of the shoe sole? (answer ...      Ridged   \n",
       "1      1  Judging by the image, what is the rust-resista...       Brown   \n",
       "2      2  What color is the lid of the 365 Everyday Valu...       Green   \n",
       "3      3  Judging from the image, what color is the \"Who...       White   \n",
       "4      4  Considering the Rivet Theresa chair's upholste...      Dotted   \n",
       "5      5  Given the \"Boy and Girl\" design, what shape ar...      Hearts   \n",
       "6      6  Based on the AmazonBasics mat's double-dot tex...    Non-slip   \n",
       "7      7  What color is the handle of the garden tool? (...        Blue   \n",
       "8      8  What design is printed on the cups? (answer in...      Leaves   \n",
       "9      9  What color is the plumbing fixture shown in th...       Black   \n",
       "\n",
       "  Prediction  BLEU-1  Match  \n",
       "0    stripes     0.0  False  \n",
       "1       rust     0.0  False  \n",
       "2      green     1.0   True  \n",
       "3      brown     0.0  False  \n",
       "4      tweed     0.0  False  \n",
       "5      heart     0.0  False  \n",
       "6       high     0.0  False  \n",
       "7       blue     1.0   True  \n",
       "8       leaf     0.0  False  \n",
       "9     silver     0.0  False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BlipProcessor, BlipForQuestionAnswering\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "#  Load CSV and define image path\n",
    "df = pd.read_csv('/kaggle/input/actual-dataset/final.csv')\n",
    "dataset_dir = '/kaggle/input/images/abo-images-small/images/small'\n",
    "\n",
    "#  Take a random sample of 30,000 rows\n",
    "df = df.sample(n=20000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#  Load BLIP VQA base model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-vqa-base\")\n",
    "model = BlipForQuestionAnswering.from_pretrained(\"Salesforce/blip-vqa-base\").to(device)\n",
    "\n",
    "#  Evaluation setup\n",
    "results = []\n",
    "smoothie = SmoothingFunction().method1\n",
    "bleu_scores = []\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    row = df.iloc[i]\n",
    "    img_path = os.path.join(dataset_dir, row['path'])\n",
    "\n",
    "    try:\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "    except:\n",
    "        print(f\"Could not open image {img_path}\")\n",
    "        continue\n",
    "\n",
    "    question = str(row['Question']).strip() if pd.notnull(row['Question']) else \"\"\n",
    "    true_answer = str(row['Answer']).strip() if pd.notnull(row['Answer']) else \"\"\n",
    "\n",
    "    question += \" (answer in one word)\"\n",
    "\n",
    "    inputs = processor(image, question, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(**inputs,temperature=1.5)\n",
    "    pred = processor.decode(output[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    reference = [true_answer.lower().split()]\n",
    "    candidate = pred.lower().split()\n",
    "    bleu = sentence_bleu(reference, candidate, weights=(1, 0, 0, 0), smoothing_function=smoothie)\n",
    "    bleu_scores.append(bleu)\n",
    "\n",
    "    results.append({\n",
    "        'Index': i,\n",
    "        'Question': question,\n",
    "        'GroundTruth': true_answer,\n",
    "        'Prediction': pred,\n",
    "        'BLEU-1': bleu\n",
    "    })\n",
    "\n",
    "#  Convert to DataFrame and evaluate\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df['Match'] = res_df.apply(\n",
    "    lambda x: x['GroundTruth'].strip().lower() == x['Prediction'].strip().lower(),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "accuracy = res_df['Match'].mean()\n",
    "average_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "#  Save and show\n",
    "res_df.to_csv('/kaggle/working/blip_vqa_base_30k_sample_results.csv', index=False)\n",
    "print(f\"BLIP-VQA-Base Exact Match Accuracy: {accuracy:.4f}\")\n",
    "print(f\"BLIP-VQA-Base Average BLEU-1 Score: {average_bleu:.4f}\")\n",
    "res_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./blip-vqa-lora-final\")\n",
    "processor.save_pretrained(\"./blip-vqa-lora-final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7263310,
     "sourceId": 11586516,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7436855,
     "sourceId": 11837124,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
